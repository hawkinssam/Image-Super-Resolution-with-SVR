{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SVR Main.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pH36RhjF5aD5"
      },
      "source": [
        "# SVR Implementation for Image Super-resolution\n",
        "## Instructions/Explanations:\n",
        "### Each of the sections below are titled according to their purpose. If there are important notes or instructions involved with a section, they will be located under the section title and in comments.\n",
        "### After updating the \"path\" variable for the AT&T Dataset and the specific paths for the images in the USC-SIPI Database, the code can be run as-is and provide all of the results that were discussed in the report.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whlkbBFd5Z9P"
      },
      "source": [
        "# Mount Google Drive\n",
        "## This is optional, there are many ways to read in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VBCa-qE5XxF"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function: Read in Data\n",
        "## INSTRUCTIONS: If you have the data on your desktop or somewhere else, just update the \"path\" variable as needed.\n",
        "## DESCRIPTION: This function takes in a number of people to consider (40 possible), how many pictures per person for training, and how many pictures per person for testing"
      ],
      "metadata": {
        "id": "VSLWRfPys3nZ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfo-8xYaNCo1"
      },
      "source": [
        "#Read in the raw data from AT&T faces dataset\n",
        "#This function is specific to this dataset: it contains specific image size and number of pictures in the dataset\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.svm import SVR\n",
        "import os\n",
        "from PIL import Image\n",
        "import warnings\n",
        "import glob\n",
        "import matplotlib.image as mpimg\n",
        "import cv2\n",
        "\n",
        "\n",
        "def prepare_images_att(num_people,num_pic_tr,num_pic_te):\n",
        "    path = '/content/gdrive/Shareddrives/EC503 Project Team/Code/ORL-DATABASE'\n",
        "    X = []\n",
        "    y = []\n",
        "    for i in range(40):\n",
        "        for j in range(10):\n",
        "            img = Image.open(os.path.join(path +'/s'+str(i+1), str(j+1)+'.pgm'))\n",
        "            X.append(np.asarray(img, dtype=np.uint8).flatten())\n",
        "            y.append(i)\n",
        "    X = np.asarray(X) #All images\n",
        "    y = np.asarray(y) #numbered people (40 in total)\n",
        "\n",
        "\n",
        "\n",
        "    #Create the training and testing datasets\n",
        "    width = 92\n",
        "    height = 112\n",
        "    \n",
        "    \n",
        "    X=X.reshape(400,height,width)\n",
        "\n",
        "    ind=np.arange(num_people)\n",
        "    train_ind=ind*10\n",
        "    tmp=ind*10\n",
        "    \n",
        "    for i in range(num_pic_tr-1):\n",
        "        train_ind=np.concatenate([train_ind,tmp+1+i])\n",
        "        \n",
        "    train_ind=np.sort(train_ind)\n",
        "    \n",
        "    np_training_input=X[train_ind,]    \n",
        "    np_training_class=y[train_ind,]\n",
        "    \n",
        "    \n",
        "    ind=np.arange(num_people)\n",
        "    test_ind=ind*10+num_pic_tr\n",
        "    tmp=ind*10+num_pic_tr\n",
        "    for i in range(num_pic_te-1):\n",
        "        test_ind=np.concatenate([test_ind,tmp+1+i])\n",
        "        \n",
        "    test_ind=np.sort(test_ind)\n",
        "    \n",
        "    np_test_input=X[test_ind,]    \n",
        "    np_test_class=y[test_ind,]\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "    return width,height,np_training_input,np_test_input,np_training_class,np_test_class\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dxj565UXi11"
      },
      "source": [
        "# Function: Create sliding window that makes a patch at each pixel and vectorizes it\n",
        "## INSTRUCTIONS: Define a window size, the data you want turned in to patches (X and y for SVR), and the data dimensions\n",
        "## DESCRIPTION: This function makes a sliding window that makes a mxm vectorized patch for each pixel in the input, with a corresponding single pixel in the output. This becomes X and y for SVR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKJUEmRIVnUU"
      },
      "source": [
        "from sklearn.feature_extraction import image\n",
        "import numpy as np\n",
        "from numpy.lib.stride_tricks import as_strided\n",
        "\n",
        "\n",
        "def sliding_window(arr, window_size):\n",
        "    \"\"\" Construct a sliding window view of the array\"\"\"\n",
        "    arr = np.asarray(arr)\n",
        "    window_size = int(window_size)\n",
        "    if arr.ndim != 2:\n",
        "        raise ValueError(\"need 2-D input\")\n",
        "    if not (window_size > 0):\n",
        "        raise ValueError(\"need a positive window size\")\n",
        "    shape = (arr.shape[0] - window_size + 1,\n",
        "             arr.shape[1] - window_size + 1,\n",
        "             window_size, window_size)\n",
        "    if shape[0] <= 0:\n",
        "        shape = (1, shape[1], arr.shape[0], shape[3])\n",
        "    if shape[1] <= 0:\n",
        "        shape = (shape[0], 1, shape[2], arr.shape[1])\n",
        "    strides = (arr.shape[1]*arr.itemsize, arr.itemsize,\n",
        "               arr.shape[1]*arr.itemsize, arr.itemsize)\n",
        "    return as_strided(arr, shape=shape, strides=strides)\n",
        "\n",
        "def cell_neighbors(arr, i, j, d):\n",
        "    \"\"\"Return d-th neighbors of cell (i, j)\"\"\"\n",
        "    w = sliding_window(arr, 2*d+1)\n",
        "\n",
        "    ix = np.clip(i - d, 0, w.shape[0]-1)\n",
        "    jx = np.clip(j - d, 0, w.shape[1]-1)\n",
        "\n",
        "    i0 = max(0, i - d - ix)\n",
        "    j0 = max(0, j - d - jx)\n",
        "    i1 = w.shape[2] - max(0, d - i + ix)\n",
        "    j1 = w.shape[3] - max(0, d - j + jx)\n",
        "\n",
        "    return w[ix, jx][i0:i1,j0:j1].ravel()\n",
        "\n",
        "\n",
        "def pad_with(vector, pad_width, iaxis, kwargs):\n",
        "    pad_value = kwargs.get('padder', 10)\n",
        "    vector[:pad_width[0]] = pad_value\n",
        "    vector[-pad_width[1]:] = pad_value\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def get_patches(np_training_input,np_training_output,desired_dim,window_size=(5,5)):\n",
        "    \n",
        "    width=desired_dim[0]\n",
        "    height=desired_dim[1]\n",
        "    tmp=int(window_size[0]-1)\n",
        "    one_tmp=int(tmp/2)\n",
        "\n",
        "    y=np.zeros(width*height*len(np_training_input))\n",
        "    x=np.zeros((width*height*len(np_training_input),window_size[0]*window_size[1]))\n",
        "\n",
        "\n",
        "    for z in range (len(np_training_input)):\n",
        "        array_tmp=z*width*height\n",
        "        img=np_training_input[z,]\n",
        "        img_y=np_training_output[z,]\n",
        "        #zimg = np.zeros((height+tmp, width+tmp))\n",
        "        #zimg[one_tmp:height+one_tmp, one_tmp:width+one_tmp] = img\n",
        "        \n",
        "        \n",
        "        padded=np.pad(img, one_tmp, pad_with, padder=-879)\n",
        "        #print(padded)\n",
        "        cntrl=np.where(padded!=-879)\n",
        "        cntrl=(np.asarray(cntrl).T).tolist()\n",
        "        \n",
        "        patches = []\n",
        "        \n",
        "        for pos in cntrl:\n",
        "            #print(pos)\n",
        "            tmp_padded=padded[pos[0]-one_tmp:pos[0]+one_tmp+1,pos[1]-one_tmp:pos[1]+one_tmp+1]\n",
        "            #print(tmp_padded)\n",
        "            #tmp_padded=tmp_padded[tmp_padded!=-1]\n",
        "            #me_zeros.append(int(padded[pos[0],pos[1]]))\n",
        "            patches.append(tmp_padded.flatten())\n",
        "            #print(tmp_padded)\n",
        "            \n",
        "        \n",
        "        \n",
        "        #patches = image.extract_patches_2d(zimg, window_size)\n",
        "        \n",
        "        \n",
        "        y[z*width*height:(z+1)*width*height]=img_y.flatten()\n",
        "        #y=np.zeros(len(patches))\n",
        "        #x=np.zeros((len(patches),window_size[0]*window_size[1]))\n",
        "        for i in range (height):\n",
        "            for j in range (width):\n",
        "                #y[array_tmp+i*j+j]=img_y[i,j]\n",
        "                x[array_tmp+i*width+j]=patches[i*width+j].flatten()\n",
        "                \n",
        "    x[x==-879]=0\n",
        "    return(x,y)\n",
        "\n",
        "\n",
        "def get_patches_single_image(np_training_input,desired_dim,window_size=(5,5)):\n",
        "    \n",
        "    width=desired_dim[0]\n",
        "    height=desired_dim[1]\n",
        "    tmp=int(window_size[0]-1)\n",
        "    one_tmp=int(tmp/2)\n",
        "\n",
        "    y=np.zeros(width*height)\n",
        "    x=np.zeros((width*height,window_size[0]*window_size[1]))\n",
        "\n",
        "\n",
        "    \n",
        "    \n",
        "    img=np_training_input\n",
        "    #zimg = np.zeros((height+tmp, width+tmp))\n",
        "    #zimg[one_tmp:height+one_tmp, one_tmp:width+one_tmp] = img\n",
        "\n",
        "    padded=np.pad(img, one_tmp, pad_with, padder=-879)\n",
        "    #print(padded)\n",
        "    cntrl=np.where(padded!=-879)\n",
        "    cntrl=(np.asarray(cntrl).T).tolist()\n",
        "    \n",
        "    patches = []\n",
        "    \n",
        "    for pos in cntrl:\n",
        "        #print(pos)\n",
        "        tmp_padded=padded[pos[0]-one_tmp:pos[0]+one_tmp+1,pos[1]-one_tmp:pos[1]+one_tmp+1]\n",
        "        #print(tmp_padded)\n",
        "        #tmp_padded=tmp_padded[tmp_padded!=-1]\n",
        "        #me_zeros.append(int(padded[pos[0],pos[1]]))\n",
        "        patches.append(tmp_padded.flatten())\n",
        "        #print(tmp_padded)\n",
        "    \n",
        "    #patches = image.extract_patches_2d(zimg, window_size)\n",
        "    \n",
        "    \n",
        "    \n",
        "    #y=np.zeros(len(patches))\n",
        "    #x=np.zeros((len(patches),window_size[0]*window_size[1]))\n",
        "    for i in range (height):\n",
        "        for j in range (width):\n",
        "            #y[i*j+j]=img[i,j]\n",
        "            x[i*width+j]=patches[i*width+j].flatten()\n",
        "                \n",
        "    y=img.flatten()\n",
        "    return(x,y)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQOiUoLuXfyE"
      },
      "source": [
        "# Function: Resize images and (optionally) add blur\n",
        "## INSTRUCTIONS: Define what images you want resized and/or blurred, the new size they are to be, and whether or not you want to add a Gaussian blur (true/false)\n",
        "## DESCRIPTION: This function takes a set of images and resizes them, and can also simultaneously add a Gaussian blur to them.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1SgjipvV-fN"
      },
      "source": [
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def add_blur_decrease_size(np_training_input,desired_dim,add_blur=False):\n",
        "    \n",
        "    \n",
        "    no_of_training=len(np_training_input)\n",
        "    \n",
        "    \n",
        "    training_input=[None]*no_of_training\n",
        "    \n",
        "    \n",
        "    for i in range(no_of_training):\n",
        "        tr=np_training_input[i,]\n",
        "        if add_blur==True:\n",
        "            tr = cv2.GaussianBlur(tr, (3,3),0)\n",
        "        resized = cv2.resize(tr, desired_dim)\n",
        "        training_input[i]=resized\n",
        "        \n",
        "    \n",
        "    width=desired_dim[0]\n",
        "    height=desired_dim[1]\n",
        "    training_input=np.array(training_input)\n",
        "    \n",
        "    \n",
        "    return width,height,training_input"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Function: Evaluate performance of predicted images\n",
        "## INSTRUCTIONS: In array format, input the HR test images, the interpolated test images, and the corresponding predictions. This function can output averages, or all values in vector format\n",
        "## DESCRIPTION: This function calculates the PSNR, MSE, and SSIM for all of the interpolated images and SVR predicted images, both compared to their corresponding HR image. \n"
      ],
      "metadata": {
        "id": "duA0HCFe78Ef"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import skimage\n",
        "from skimage import metrics\n",
        "from tabulate import tabulate\n",
        "\n",
        "\n",
        "def mse_psnr_ssim(all_hr_test,all_lr_test,all_predictions):\n",
        "    #all_hr_test are the originals\n",
        "    #all_lr_test are the interopolated\n",
        "    #all_predictions are the predictions\n",
        "\n",
        "    interp_psnr=[]\n",
        "    interp_mse=[]\n",
        "    svr_psnr=[]\n",
        "    svr_mse=[]\n",
        "    interp_ssim=[]\n",
        "    svr_ssim=[]\n",
        "    #Calculate different metrics between HR-LR, and between HR-reconstructed\n",
        "    #Calculates PSNR, MSE, and SSIM for all test and prediction examples\n",
        "    for i in range(len(all_hr_test)):\n",
        "        #Peak Signal to Noise Ratio\n",
        "        interp_psnr.append( cv2.PSNR(all_hr_test[i].astype(float),all_lr_test[i].astype(float)))\n",
        "        svr_psnr.append( cv2.PSNR(all_hr_test[i].astype(float),all_predictions[i]))\n",
        "        #Mean-Squared Error\n",
        "        interp_mse.append(skimage.metrics.mean_squared_error(all_hr_test[i].astype(float),all_lr_test[i].astype(float)))\n",
        "        svr_mse.append( skimage.metrics.mean_squared_error(all_hr_test[i].astype(float),all_predictions[i]))\n",
        "        #Structural Similarity Index Measure\n",
        "        interp_ssim.append(skimage.metrics.structural_similarity(all_hr_test[i].astype(float),all_lr_test[i].astype(float)))\n",
        "        svr_ssim.append(skimage.metrics.structural_similarity(all_hr_test[i].astype(float),all_predictions[i].astype(float)))\n",
        "    print(f\"Interpolated PSNR: {interp_psnr}\")\n",
        "    print(f\"Reconstructed PSNR: {svr_psnr}\")\n",
        "    print(f\"Interopolated SSIM: {interp_ssim}\")\n",
        "    print(f\"Reconstructed SSIM: {svr_ssim}\")\n",
        "    #take mean of each metric over all test images\n",
        "    #print(\"Average test psnr between HR and interpolated: \", str(np.mean(np.array(interp_psnr))))\n",
        "    #print(\"Average test psnr between HR and SVR predicted: \", str(np.mean(np.array(svr_psnr))))\n",
        "    #print(\"Average test mse between HR and interpolated: \", str(np.mean(np.array(interp_mse))))\n",
        "    #print(\"Average test mse between HR and SVR predicted: \", str(np.mean(np.array(svr_mse))))\n",
        "    #print(\"Average test SSIM between HR and interpolated: \", str(np.mean(np.array(interp_ssim))))\n",
        "    #print(\"Average test SSIM between HR and SVR predicted: \", str(np.mean(np.array(svr_ssim))))\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "    return \n"
      ],
      "metadata": {
        "id": "WCVD60wGOBKG"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Function: Create triplet plot showing original image, interpolated image, and super-resolved image side-by-side\n",
        "## INSTRUCTIONS: Input single HR image, interpolated image, and SVR reconstructed image\n",
        "## DESCRIPTION: This function will output a triplet plot to visualize how well the SVR model did to predict a HR image compared to interpolation"
      ],
      "metadata": {
        "id": "ebTBkD1d8LC9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a triplet plot showing an HR image, it's interpolated counterpart, and the predicted HR image reconstructed using SVR\n",
        "def triplet_plot(hr_image,interp_image,reconstructed_image):\n",
        "    #Plot high res, low res(interpolated), and super-resolved\n",
        "    fig1 = plt.figure(1)\n",
        "    fig1.set_figheight(10)\n",
        "    fig1.set_figwidth(10)\n",
        "    ax1 = plt.subplot2grid(shape=(9,9), loc=(0, 0), rowspan=2, colspan=2)\n",
        "    ax2 = plt.subplot2grid(shape=(9,9), loc=(0, 3), rowspan=2, colspan=2)\n",
        "    ax3 = plt.subplot2grid(shape=(9,9), loc=(0, 6), rowspan=2, colspan=2)\n",
        "    # plotting subplots\n",
        "    ax1.imshow(hr_image, cmap='binary_r',label=\"dasd\")\n",
        "    ax1.set_title('Original Image')\n",
        "    ax2.imshow(interp_image, cmap='binary_r',label=\"dasd\")\n",
        "    ax2.set_title('Interpolated Image')\n",
        "    ax3.imshow(reconstructed_image, cmap='binary_r',label=\"dasd\")\n",
        "    ax3.set_title('Predicted Image')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return\n"
      ],
      "metadata": {
        "id": "esyrmndDGr7o"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate Training and Testing Data\n",
        "## DESCRIPTION: Defines number of people (out of 40) to consider, and how many pictures will be used per person to train and test\n"
      ],
      "metadata": {
        "id": "k5revttUulVr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_people=20\n",
        "num_tr=3\n",
        "num_te=1\n",
        "\n",
        "#Will create a training dataset of 60 images, and testing set of 20 images\n",
        "width,height,np_training_input,np_test_input,np_training_class,np_test_class = prepare_images_att(num_people,num_tr,num_te)\n",
        "\n",
        "no_of_tr_pictures=len(np_training_input)\n",
        "no_of_test_pictures=len(np_test_input)\n",
        "\n",
        "tr_input_row=np_training_input.reshape(no_of_tr_pictures,height*width)\n",
        "test_input_row=np_test_input.reshape(no_of_test_pictures,height*width)"
      ],
      "metadata": {
        "id": "8VHgy60uup6y"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Downsize then upsize images to create blur effect\n",
        "## DESCRIPTION: The cell below is creating the HR and LR images. To make computation time significantly better, the original 112x92 images are initially resized to 64x64. These 64x64 images will act as the \"HR\" images for the remainder of the training and testing of the AT&T faces"
      ],
      "metadata": {
        "id": "h52uDgtjvAph"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#We will downsize HR images of original size to 64x64 first. the first 64x64 will act as the \"HR\" images\n",
        "downsize_dim = (64,64)\n",
        "width,height,hr_train = add_blur_decrease_size(np_training_input,downsize_dim,add_blur=False)\n",
        "width,height,hr_test = add_blur_decrease_size(np_test_input,downsize_dim,add_blur=False)\n",
        "\n",
        "downsize_dim = (32,32)\n",
        "width,height,lr_train = add_blur_decrease_size(hr_train,downsize_dim,add_blur=False)\n",
        "width,height,lr_test = add_blur_decrease_size(hr_test,downsize_dim,add_blur=False)\n",
        "\n",
        "#the LR images of size 64x64 are blurry compared to the HR images of 64x64\n",
        "upsize_dim = (64,64)\n",
        "width,height,lr_train = add_blur_decrease_size(lr_train,upsize_dim,add_blur=False)\n",
        "width,height,lr_test = add_blur_decrease_size(lr_test,upsize_dim,add_blur=False)\n"
      ],
      "metadata": {
        "id": "s31z8cRLvLyl"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate Patches\n",
        "## DESCRIPTION: The cell below takes the images that were resized above, and turns them into patches. These patches are fed into the SVR model for training and prediction. It is important to note that while we are creating a \"ytest\" variable, this is not used in prediction. This means that the SVR model is going to predict \"ytest\" given the unseen \"xtest\" patches"
      ],
      "metadata": {
        "id": "PGslBLwWu7qT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Sliding window size\n",
        "w_size = (5,5)\n",
        "\n",
        "#Define training X and y patches\n",
        "xtrain,ytrain = get_patches(lr_train.astype(float),hr_train,upsize_dim,w_size)\n",
        "\n",
        "#Create testing patches\n",
        "xtest,ytest=get_patches(lr_test.astype(float),hr_test,upsize_dim,w_size)\n"
      ],
      "metadata": {
        "id": "9O85QrMeu-2u"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train SVR model and make prediction\n",
        "## DESCRIPTION: First, this cell defines how many patches will be randomly sampled and used for training. These X patches, along with their corresponding HR output y, are fed into sklearn's SVR model. Predictions are made based on the xtest patches. Next, the predictions are resized to be of proper image shape\n",
        "## NOTE: For reference, training 30% of the patches takes about 31.5 minutes, and this time is scaled more than quadratically with increases. "
      ],
      "metadata": {
        "id": "Rkl1Rxdz0x27"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVR\n",
        "from sklearn.svm import NuSVR\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import random\n",
        "import time\n",
        "\n",
        "\n",
        "#choose percentage of the patches to train on\n",
        "how_many_patches_to_train = int(.3*len(xtrain))       #30% of patches\n",
        "ind = random.sample(range(0,len(xtrain)),how_many_patches_to_train)   \n",
        "\n",
        "xtrain_sampled = xtrain[ind]\n",
        "ytrain_sampled = ytrain[ind]\n",
        "\n",
        "#Make_pipeline and standard scaler are used to normalize data\n",
        "regr = make_pipeline(StandardScaler(), SVR(C=350, epsilon=2))\n",
        "start = time.time()\n",
        "svr = regr.fit(xtrain_sampled, ytrain_sampled)\n",
        "end = time.time()\n",
        "print(f\"Training time for {len(xtrain_sampled)} patches is {end - start} seconds\")\n",
        "\n",
        "#this will make a prediction for all of the test images\n",
        "#start = time.time()\n",
        "prediction=svr.predict(xtest)\n",
        "end2 = time.time()\n",
        "print(f\"Time to make prediction on {len(xtest)} patches is {end2 - end} seconds\")\n",
        "\n",
        "#Extract all prediction images into correct sizes\n",
        "prediction_pics = prediction.reshape(-1,height,width)\n",
        "\n"
      ],
      "metadata": {
        "id": "uv-R5uUs0538"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot all of the images you predicted"
      ],
      "metadata": {
        "id": "tdXH8pzeI492"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(prediction_pics)):\n",
        "    triplet_plot(hr_test[i],lr_test[i],prediction_pics[i])"
      ],
      "metadata": {
        "id": "lPMdg4C3YHgj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Print all of the PSNR and SSIM values for predictions and interpolated images"
      ],
      "metadata": {
        "id": "ItPdt9J1JAGZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mse_psnr_ssim(hr_test,lr_test,prediction_pics)"
      ],
      "metadata": {
        "id": "M0xv5_t1I2lz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Test on Images from USC SIPI database\n",
        "## INSTRUCTIONS: Download images from the \"Miscellaneous\" tab of the USC SIPI Image Database: Filenames - 4.1.01 (girl), 5.1.12 (clock), house (house), 5.1.13 (resolution chart) and read them in like below\n",
        "## DESCRIPTION: The cell below takes in a few downloaded images from the USC SIPI Image Database and explores how the SVR model trained above performs "
      ],
      "metadata": {
        "id": "GGbwMRwSEJoC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#load in 4 pictures from USC SIPI database\n",
        "clock = cv2.imread('/content/gdrive/Shareddrives/EC503 Project Team/Code/clock.tiff')\n",
        "house = cv2.imread('/content/gdrive/Shareddrives/EC503 Project Team/Code/house.tiff')\n",
        "girl = cv2.imread('/content/gdrive/Shareddrives/EC503 Project Team/Code/girl.tiff')\n",
        "chart = cv2.imread('/content/gdrive/Shareddrives/EC503 Project Team/Code/res_chart.tiff')\n",
        "\n",
        "#Convert to grayscale\n",
        "clock = cv2.cvtColor(clock, cv2.COLOR_BGR2GRAY)\n",
        "house = cv2.cvtColor(house, cv2.COLOR_BGR2GRAY)\n",
        "girl = cv2.cvtColor(girl, cv2.COLOR_BGR2GRAY)\n",
        "chart = cv2.cvtColor(chart, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "#Combine into single array\n",
        "sipi = np.zeros((4,256,256))\n",
        "sipi[0]=clock\n",
        "sipi[1]=house\n",
        "sipi[2]=girl\n",
        "sipi[3]=chart\n",
        "\n",
        "#Downscale then upcale to blur: first downscale is to decrease computational complexity. The 128x128 will be our \"HR\"\n",
        "downsize_dim = (128,128)\n",
        "width,height,hr_test = add_blur_decrease_size(sipi,downsize_dim,add_blur=False)\n",
        "\n",
        "downsize_dim = (64,64)\n",
        "width,height,interp_test = add_blur_decrease_size(hr_test,downsize_dim,add_blur=False)\n",
        "\n",
        "upsize_dim = (128,128)\n",
        "width,height,interp_test = add_blur_decrease_size(interp_test,upsize_dim,add_blur=False)\n",
        "\n",
        "#extract patches\n",
        "sipi_test=get_patches(interp_test.astype(float),hr_test,upsize_dim,w_size)[0]\n",
        "\n",
        "#Predict\n",
        "sipi_prediction = svr.predict(sipi_test)\n",
        "sipi_prediction_pics = sipi_prediction.reshape(-1,height,width)\n",
        "\n",
        "#Show results: all PSNR, SSIM values and the corresponding plots\n",
        "mse_psnr_ssim(hr_test,interp_test,sipi_prediction_pics)\n",
        "for i in range(len(sipi)):\n",
        "    triplet_plot(hr_test[i],interp_test[i],sipi_prediction_pics[i])"
      ],
      "metadata": {
        "id": "aCkPoZBbyRQo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#END\n",
        "## Code following is supplemental"
      ],
      "metadata": {
        "id": "cmeFkY6VKkK1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Use Cross-Validation to determine optimized C and epsilon values for SVR (One time only)"
      ],
      "metadata": {
        "id": "VgDedRZEIsmR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"from sklearn.svm import SVR\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "regressor = SVR()\n",
        "param_grid = {\n",
        "                 'C': [1, 100, 350, 1000, 100000],\n",
        "                 'epsilon': [0.01, 0.1, 1, 2, 10]\n",
        "             }\n",
        "# GridSearchCV automatically gives back the best parameters\n",
        "\n",
        "grid_regressor = GridSearchCV(regressor, param_grid, cv=2, n_jobs=-1, verbose=4)\n",
        "grid_regressor.fit(xtrain_sampled, ytrain_sampled)\n",
        "  \n",
        "print(grid_regressor.best_params_)\n",
        "\n",
        "#Best parameters of the above options:\n",
        "#{'C': 350, 'epsilon': 2}\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4R3gy0kLgS1o",
        "outputId": "2becede0-52ac-4c71-b5b2-ea3c750ac574"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 2 folds for each of 25 candidates, totalling 50 fits\n",
            "{'C': 350, 'epsilon': 2}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Export to CSV in Drive"
      ],
      "metadata": {
        "id": "eFMwOhYx_rga"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Write to csv\n",
        "\"\"\"import csv\n",
        "prediction_by_row = prediction.reshape(no_of_test_pictures,-1)\n",
        "pd.DataFrame(prediction_by_row).to_csv(\"/content/gdrive/Shareddrives/EC503 Project Team/Code/predictions.csv\",header=None,index=None)\"\"\""
      ],
      "metadata": {
        "id": "LTRK2z1YsynZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SSIM and PSNR comparison for single image"
      ],
      "metadata": {
        "id": "pWAjutgqKtf0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "interp_psnr = cv2.PSNR(hr_test[2].astype(float),lr_test[2].astype(float))\n",
        "svr_psnr= cv2.PSNR(hr_test[2].astype(float),prediction_pics[2])\n",
        "\n",
        "interp_ssim = skimage.metrics.structural_similarity(hr_test[2].astype(float),lr_test[2].astype(float))\n",
        "svr_ssim = skimage.metrics.structural_similarity(hr_test[2].astype(float),prediction_pics[2].astype(float))\n",
        "\n",
        "print(f\"PSNR between HR and interpolated:{interp_psnr} \")\n",
        "print(f\"PSNR between HR and SVR predicted:{svr_psnr} \")\n",
        "\n",
        "print(f\"SSIM between HR and interpolated:{interp_ssim} \")\n",
        "print(f\"SSIM between HR and SVR predicted:{svr_ssim} \")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WcZhHgt4pIH0",
        "outputId": "4627e27a-a9d1-4e4e-dd44-9f737b60e4da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PSNR between HR and interpolated:29.94717199215199 \n",
            "PSNR between HR and SVR predicted:32.70989310505532 \n",
            "SSIM between HR and interpolated:0.9004381716521832 \n",
            "SSIM between HR and SVR predicted:0.9503070510189855 \n"
          ]
        }
      ]
    }
  ]
}